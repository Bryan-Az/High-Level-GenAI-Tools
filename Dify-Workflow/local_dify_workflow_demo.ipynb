{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dify's Local Workflow API in Python\n",
    "Using the free API's provided by Dify.ai, Cohere's Rerank LLM, Tavily for Online Search, Jina for Embedding Optimization, as well GPT for prompt optimization and iteration of online search results.\n",
    "\n",
    "Given the multiple components of this workflow, as well as the number of iterations, many tokens and API's are called with this single query. It ranges in time from 1 minute or longer depending on the query asked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"task_id\": \"4915cfb9-3907-4279-922b-8cc292ee90b6\", \"workflow_run_id\": \"310841ab-0bd8-4e20-94f6-500cf1bd2c8e\", \"data\": {\"id\": \"310841ab-0bd8-4e20-94f6-500cf1bd2c8e\", \"workflow_id\": \"20596524-4c55-4244-8e3d-99ac0f5f129b\", \"status\": \"succeeded\", \"outputs\": {\"text\": \"|URL|Summary|\\n|---|---|\\n|https://github.com/immersivecognition/unity-experiment-framework|The text is a detailed overview of the Unity Experiment Framework (UXF) designed for creating human behavior experiments using the Unity engine. UXF supports VR, desktop, and web-based experiments, enabling remote data collection with various output modes. Developed by Jack Brookes from the Immersive Cognition Group at the University of Leeds, the framework includes numerous features such as automated data collection, event handling, settings management, and a customizable user interface. It is compatible with Unity 2018.4 LTS and newer versions. The text also discusses how to get started with UXF, provides examples, and links to documentation and a tutorial. Additionally, it highlights the framework's usage in research and media coverage.|\\n|https://developer.oculus.com/blog/free-oculus-unity-vr-development-course/|Oculus and Unity have teamed up to offer a free, 11-unit VR development course aimed at intermediate Unity developers. This comprehensive course covers various aspects of VR development, from design and prototyping to performance optimization and market strategy. Each unit is led by experts from Oculus and Unity, offering in-depth knowledge on topics such as spatial sound design, locomotion, hand presence, and UI best practices. Participants will build a vertical slice of an escape room game and can submit their work for feedback from Oculus Developer Support. The course is self-paced, requires Unity 2018.4 LTS, and is designed to take 25-30 hours to complete. For more details, visit the [Oculus blog](https://developer.oculus.com/blog/free-oculus-unity-vr-development-course/).|\\n|https://learn.unity.com/course/oculus-vr|The text contains metadata for an online course titled \\\"Oculus VR\\\" available on Unity's learning platform. The course appears to be referred to as \\\"rpiframe,\\\" and the URL provided is \\\"https://learn.unity.com/course/oculus-vr\\\". The data usage indicates minimal token consumption.|\\n|https://learn.unity.com/tutorial/unit-3-using-unity-to-develop-vr-experiences|The text provides a link to a Unity tutorial titled \\\"Unit 3: Using Unity to Develop VR Experiences.\\\"|\\n|https://developer.prod.oculus.com/unity/|The text provides a comprehensive guide for developing VR apps using Unity 3D for Oculus devices. It highlights Unity 3D as a powerful real-time 3D engine suitable for both beginners and expert developers. The Oculus Integration package, available on the Unity Asset Store and Oculus Developer Center, includes essential components, prefabs, game objects, and APIs to aid in VR app development. Key features include OVRManager for hardware integration, OVRInput for controller customization, and OVRHaptics for precise haptic feedback. The text also mentions sample VR projects for learning and experimenting. Additionally, there is a free 11-unit video course on VR development offered in partnership with Unity, covering performance optimization, locomotion, playtesting, and VR game marketing. For beginners, the text recommends starting with Unity Learn and the Unity User Manual. Students are encouraged to use the Unity Student Plan for free benefits.|\\n\"}, \"error\": null, \"elapsed_time\": 55.26495085700299, \"total_tokens\": 10075, \"total_steps\": 22, \"created_at\": 1725576442, \"finished_at\": 1725576485}}\n"
     ]
    }
   ],
   "source": [
    "url = \"http://localhost/v1/workflows/run\"\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f\"Bearer {os.getenv('INTERNET_AND_RAG_SEARCH_KEY')}\",\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"inputs\": {\"Question\": \"low cost prototype guides developing a VR App with Unity Experiment Framework on Oculus device HMI\"},\n",
    "    \"user\": \"user1\",\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "response_json = json.loads(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "|URL|Summary|\n",
       "|---|---|\n",
       "|https://github.com/immersivecognition/unity-experiment-framework|The text is a detailed overview of the Unity Experiment Framework (UXF) designed for creating human behavior experiments using the Unity engine. UXF supports VR, desktop, and web-based experiments, enabling remote data collection with various output modes. Developed by Jack Brookes from the Immersive Cognition Group at the University of Leeds, the framework includes numerous features such as automated data collection, event handling, settings management, and a customizable user interface. It is compatible with Unity 2018.4 LTS and newer versions. The text also discusses how to get started with UXF, provides examples, and links to documentation and a tutorial. Additionally, it highlights the framework's usage in research and media coverage.|\n",
       "|https://developer.oculus.com/blog/free-oculus-unity-vr-development-course/|Oculus and Unity have teamed up to offer a free, 11-unit VR development course aimed at intermediate Unity developers. This comprehensive course covers various aspects of VR development, from design and prototyping to performance optimization and market strategy. Each unit is led by experts from Oculus and Unity, offering in-depth knowledge on topics such as spatial sound design, locomotion, hand presence, and UI best practices. Participants will build a vertical slice of an escape room game and can submit their work for feedback from Oculus Developer Support. The course is self-paced, requires Unity 2018.4 LTS, and is designed to take 25-30 hours to complete. For more details, visit the [Oculus blog](https://developer.oculus.com/blog/free-oculus-unity-vr-development-course/).|\n",
       "|https://learn.unity.com/course/oculus-vr|The text contains metadata for an online course titled \"Oculus VR\" available on Unity's learning platform. The course appears to be referred to as \"rpiframe,\" and the URL provided is \"https://learn.unity.com/course/oculus-vr\". The data usage indicates minimal token consumption.|\n",
       "|https://learn.unity.com/tutorial/unit-3-using-unity-to-develop-vr-experiences|The text provides a link to a Unity tutorial titled \"Unit 3: Using Unity to Develop VR Experiences.\"|\n",
       "|https://developer.prod.oculus.com/unity/|The text provides a comprehensive guide for developing VR apps using Unity 3D for Oculus devices. It highlights Unity 3D as a powerful real-time 3D engine suitable for both beginners and expert developers. The Oculus Integration package, available on the Unity Asset Store and Oculus Developer Center, includes essential components, prefabs, game objects, and APIs to aid in VR app development. Key features include OVRManager for hardware integration, OVRInput for controller customization, and OVRHaptics for precise haptic feedback. The text also mentions sample VR projects for learning and experimenting. Additionally, there is a free 11-unit video course on VR development offered in partnership with Unity, covering performance optimization, locomotion, playtesting, and VR game marketing. For beginners, the text recommends starting with Unity Learn and the Unity User Manual. Students are encouraged to use the Unity Student Plan for free benefits.|\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "html_content = response_json['data']['outputs']['text']\n",
    "display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dify provides a easy to use graphical interface that makes it easy to communicate across multiple LLM models and their API's using workflows. They also provide an 'explore' page that let's you search for pre-existing and open-source workflow templates. Finally, they allow you to create a 'knowledge' store containing data in multiple file formats to power Retrieval Augmented Generation (RAG), as well as providing a way to connect to pre-existing stores (i.e project management with notion, and an API that connects with Firecrawl to process website data)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-env)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
