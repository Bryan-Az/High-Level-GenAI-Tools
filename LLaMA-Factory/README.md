# LLaMA Factory & HuggingFace for Fine-tuning Specialized Models 

In this section, given an API connection to HuggingFace, a variety of model backbones (i.e lora/qlora) are utilized within LLaMA-Factorys' supervised finetuning and reinforcement training (i.e Direct Policy Optimization (DPO) and Proximal Policy Optimization (PPO)) functionalities to build specialized machine learning models.