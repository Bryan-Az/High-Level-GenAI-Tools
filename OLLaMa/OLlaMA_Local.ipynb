{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLlaMA for Running LLM's Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports requires to communicate with the local api\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing XTerm / Initializing OLlaMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is running locally, I could install OLlaMA and have it started/initialized by downloading it using the MacOS installer provided on the [ollama.com](https://ollama.com) website. Similarly, I don't need to install XTerm to interact with the OLlaMA model or API as the local jupyter notebook is not running on a colab environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the OLlaMA API to run LLMs (LlaMA 3, Gemma 2b) and Multimodal (Llava-LlaMA)  Models\n",
    "All models are given the same prompt: to take the role of a journalist who cites their responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the run_ollama.sh script is not needed anymore as it is running and initialized locally\n",
    "# instead, we can directly communicate with the api using the requests library\n",
    "data = {\n",
    "    \"name\": \"local_llama3\",\n",
    "    \"modelfile\": \"FROM llama3\\nSYSTEM You are an avid journalist. When questioned about news, you always cite multiple sources as evidence.\"\n",
    "}\n",
    "\n",
    "response_to_create_endpoint = requests.post('http://localhost:11434/api/create', json=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_to_create_endpoint #implies a successful creation of the llama3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"name\": \"local_gemma2b\",\n",
    "    \"modelfile\": \"FROM gemma2\\nSYSTEM You are an avid journalist. When questioned about news, you always cite multiple sources as evidence.\"\n",
    "}\n",
    "\n",
    "response_to_create_endpoint = requests.post('http://localhost:11434/api/create', json=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_to_create_endpoint #implies a successful creation of the gemma2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"name\": \"local_llava-llama3\",\n",
    "    \"modelfile\": \"FROM llava-llama3\\nSYSTEM You are an avid journalist. When questioned about news, you always cite multiple sources as evidence.\"\n",
    "}\n",
    "\n",
    "response_to_create_endpoint = requests.post('http://localhost:11434/api/create', json=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_to_create_endpoint #implies a successful creation of the llava-llama3 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Status of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_models = requests.get('http://localhost:11434/api/tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [{'name': 'llava-llama3:latest',\n",
       "   'model': 'llava-llama3:latest',\n",
       "   'modified_at': '2024-09-12T16:25:45.002747603-07:00',\n",
       "   'size': 5545682182,\n",
       "   'digest': '44c161b1f46523301da9c0cc505afa4a4a0cc62f580581d98a430bb21acd46de',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama', 'clip'],\n",
       "    'parameter_size': '8B',\n",
       "    'quantization_level': 'Q4_K_M'}},\n",
       "  {'name': 'local_llava-llama3:latest',\n",
       "   'model': 'local_llava-llama3:latest',\n",
       "   'modified_at': '2024-09-12T16:25:45.020100703-07:00',\n",
       "   'size': 5545682359,\n",
       "   'digest': 'd625ea08843b09c46106fcfb2f179a551b43cc1851fb44a995bf6be801674342',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama', 'clip'],\n",
       "    'parameter_size': '8.0B',\n",
       "    'quantization_level': 'Q4_K_M'}},\n",
       "  {'name': 'local_gemma2b:latest',\n",
       "   'model': 'local_gemma2b:latest',\n",
       "   'modified_at': '2024-09-12T16:11:56.374821872-07:00',\n",
       "   'size': 5443152592,\n",
       "   'digest': 'a95850566c2fce93cfd42e562e80f23b79d502c5416d1170a5476540e84ee50b',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'gemma2',\n",
       "    'families': ['gemma2'],\n",
       "    'parameter_size': '9.2B',\n",
       "    'quantization_level': 'Q4_0'}},\n",
       "  {'name': 'llama3:latest',\n",
       "   'model': 'llama3:latest',\n",
       "   'modified_at': '2024-09-12T16:06:36.583380806-07:00',\n",
       "   'size': 4661224676,\n",
       "   'digest': '365c0bd3c000a25d28ddbf732fe1c6add414de7275464c4e4d1c3b5fcb5d8ad1',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '8.0B',\n",
       "    'quantization_level': 'Q4_0'}},\n",
       "  {'name': 'local_llama3:latest',\n",
       "   'model': 'local_llama3:latest',\n",
       "   'modified_at': '2024-09-12T16:06:36.597375701-07:00',\n",
       "   'size': 4661224851,\n",
       "   'digest': '4b35c18ac1884b563a225184ba561f07e8d0cc316f5251840857d02cd76eba33',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '8.0B',\n",
       "    'quantization_level': 'Q4_0'}},\n",
       "  {'name': 'gemma2:latest',\n",
       "   'model': 'gemma2:latest',\n",
       "   'modified_at': '2024-09-12T14:48:44.394265166-07:00',\n",
       "   'size': 5443152417,\n",
       "   'digest': 'ff02c3702f322b9e075e9568332d96c0a7028002f1a5a056e0a6784320a4db0b',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'gemma2',\n",
       "    'families': ['gemma2'],\n",
       "    'parameter_size': '9.2B',\n",
       "    'quantization_level': 'Q4_0'}}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_models.json() #implies that the models are available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the json above, the models created locally are available - along with the non-local models that were created within the remote colab environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the OLLaMA API to run Inference on the Models\n",
    "Although the OLLaMA API supports stream, I'll be using the non-stream request version to chat with the models to simplify the showcase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama3_chat_data = {\n",
    "    \"model\": \"local_llama3:latest\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the most recent news you have of the 2024 election? Provide the specific dates.\"\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "response_to_llama3_chat = requests.post('http://localhost:11434/api/chat', json=llama3_chat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xw/3171xwyj1959c4pj92zw_9640000gn/T/ipykernel_32156/475722227.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "As a diligent journalist, I'm happy to provide you with the latest updates on the 2024 election! According to my trusted sources, including CNN, NBC News, and The New York Times (dates: March 15-20, 2023), here are some key takeaways:\n",
       "\n",
       "1. **Candidate Lineup**: As of now, there are over 20 declared candidates vying for the Democratic nomination, with heavyweights like Joe Biden, Bernie Sanders, and Elizabeth Warren expected to dominate the early stages. On the Republican side, Donald Trump, Mike Pence, and Ron DeSantis are among the top contenders (Source: CNN, March 15, 2023).\n",
       "2. **Policy Focus**: The campaign is already heating up, with candidates focusing on pressing issues like climate change, healthcare reform, and economic inequality. For instance, Pete Buttigieg has been touting his Medicare-for-All plan, while Tulsi Gabbard has emphasized her opposition to US involvement in foreign conflicts (Source: NBC News, March 18, 2023).\n",
       "3. **Fundraising**: As reported by The Hill (March 19, 2023), Senator Kamala Harris has already raised over $20 million, placing her among the top fundraisers. On the Republican side, Trump's campaign has raked in over $50 million, largely due to his massive social media following.\n",
       "4. **Endorsements**: Interestingly, several prominent Democrats have already endorsed candidates, such as Senator Chuck Schumer backing Biden and former First Lady Michelle Obama supporting Harris (Source: The New York Times, March 20, 2023). On the Republican side, Trump has received endorsements from high-profile figures like Senator Lindsey Graham and Governor Chris Christie.\n",
       "\n",
       "These updates are based on credible sources and should give you a solid understanding of the current state of play in the 2024 election. As more news emerges, I'll be sure to keep you informed!"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "response_content = response_to_llama3_chat.json()['message']['content']\n",
    "display(HTML(response_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma2_chat_data = {\n",
    "    \"model\": \"local_gemma2b:latest\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\":  \"What is the most recent news you have of the 2024 election? Provide the specific dates.\"\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "response_to_gemma2_chat = requests.post('http://localhost:11434/api/chat', json=gemma2_chat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "As an AI, I don't have access to real-time information, including breaking news about the 2024 election. My knowledge is based on the data I was trained on, which has a cutoff point.\n",
       "\n",
       "To get the most up-to-date information on the 2024 election, I recommend checking reputable news sources such as:\n",
       "\n",
       "* **The New York Times:** https://www.nytimes.com/\n",
       "* **CNN:** https://www.cnn.com/\n",
       "* **BBC News:** https://www.bbc.com/news\n",
       "* **Reuters:** https://www.reuters.com/\n",
       "* **Associated Press:** https://apnews.com/\n",
       "\n",
       "Remember to always cross-reference information from multiple sources to ensure accuracy and get a well-rounded perspective. \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_content = response_to_gemma2_chat.json()['message']['content']\n",
    "display(HTML(response_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_chat_data = {\n",
    "    \"model\": \"llava-llama3:latest\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\":  \"What is the most recent news you have of the 2024 election? Provide the specific dates.\"\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "response_to_multimodal_chat = requests.post('http://localhost:11434/api/chat', json=multimodal_chat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "As of my last knowledge update in September 2021, I do not have any information about an upcoming 2024 election. It's important to note that political events and candidate announcements can change rapidly, so it is possible that there may be new developments since my last update."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_content = response_to_multimodal_chat.json()['message']['content']\n",
    "display(HTML(response_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding an Image in Base64 for Input to LlaVA-LLaMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    return encoded_string\n",
    "\n",
    "# Example usage:\n",
    "image_path = './images/debate_image.png'\n",
    "encoded_image = encode_image_to_base64(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iVBORw0KGg'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_image[:10] # Displaying the first 10 characters of the encoded image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_image_chat_data = {\n",
    "    \"model\": \"llava-llama3:latest\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\":  \"Describe who are the people in this image:\",\n",
    "            \"image\": [encoded_image]\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "response_to_multimodal_image_chat = requests.post('http://localhost:11434/api/chat', json=multimodal_image_chat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The image features a man and a woman, both of whom appear to be quite old. They might be related as siblings or friends, possibly sharing a meal together at an elderly care facility. Their specific identities cannot be determined from the image alone, but they seem to enjoy each other's company and engage in conversation during their time together."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_content = response_to_multimodal_image_chat.json()['message']['content']\n",
    "display(HTML(response_content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-env)",
   "language": "python",
   "name": "test-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
